% !TeX spellcheck = de_DE
\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{svg}
\usepackage{float}
\usepackage{caption}
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{booktabs}
\usepackage[skip=3pt]{parskip}
\usepackage[ngerman]{babel}
\pagestyle{empty}
\titleformat*{\section}{\large\bfseries}
\titleformat*{\subsection}{\bfseries}

%
\geometry{
	a4paper,
	total={170mm,240mm},
	left=20mm,
	top=30mm,
}

\date{}
%Bitte ausfüllen
\newcommand\course{Heterogenious Computing}
\newcommand\hwnumber{\large Abschlussprojekt}
\newcommand\Name{Fabian Sponholz}
\newcommand\Neptun{1561546}

%Matheinheiten
\newcommand\m{\:\textrm{m}}
\newcommand\M{\:\Big[\textrm{m}\Big]}
\newcommand\mm{\:\textrm{mm}}
\newcommand\MM{\:\Big[\textrm{mm}\Big]}
\newcommand\un{\underline}
\newcommand\s{\:\textrm{s}}
\newcommand\bS{\:\Big[\textrm{S}\Big]}
\newcommand\ms{\:\frac{\textrm{m}}{\textrm{s}}}
\newcommand\MS{\:\Big[\frac{\textrm{m}}{\textrm{s}}\Big]}
\newcommand\mss{\:\frac{\textrm{m}}{\textrm{s}^2}}
\newcommand\MSS{\:\Big[\frac{\textrm{m}}{\textrm{s}^2}\Big]}

%Trennlinie
\newcommand\separator{\rule{\linewidth}{0.5pt}}

%Bitte nicht einstellen
\renewcommand{\figurename}{Abbildung}
\renewcommand{\tablename}{Tabelle}
\pagestyle{fancyplain}
\headheight 35pt
\lhead{\Name\\\Neptun}
\chead{\textbf{ \hwnumber}}
\rhead{\course \\ \today}
\lfoot{}
\cfoot{}
\rfoot{\small\thepage}
\headsep 1.5em

\begin{document}
	\section*{Einleitung}
	In der Vorlesung \emph{Heterogenious Computing} haben wir uns auch mit dem Programmieren von Grafikkarten befasst und dort verschiedene Schnittstellen kennengelernt, die es ermöglichen, Code direkt auf solcher Hardware auszuführen.
	Insbesondere gut parallelisierbare Aufgaben lassen sich so erheblich beschleunigen im Vergleich zur Ausführung auf einer CPU.
	Zunächst wäre da einmal \emph{OpenCL} zu nennen, welches eine offene Schnittstelle für verschiedenste Geräte wie FPGAs, CPUs und GPUs darstellt.
	Zusätzlich gibt es bei GPUs noch herstellereigene Schnittstellen wie z.B. \emph{Nvidia CUDA} oder \emph{Intel oneAPI}, die grundsätzlich ähnliche Funktionalitäten bieten.
	
	Für mein Abschlussprojekt stelle ich mir die Frage, ob die Verwendung von herstellerspezifischen APIs im Vergleich zu OpenCL einen signifikanten Performance-Vorteil bringt.
	Dazu möchte ich je einen rechenintensiven Algorithmus zur Messung der Rechenleistung und einen speicherintensiven Algorithmus zur Messung der Speicherbandbreite implementieren.
	Diese Algorithmen werde ich für verschiedene Schnittstellen anpassen und so die Performance (Laufzeit) vergleichen.
	
	\subsection*{Gewählte Algorithmen}
	Folgende Algorithmen habe ich für das Experiment ausgewählt:
	
	\begin{itemize}
		\item \textbf{Matrix-Multiplikation} ist eine einfache aber rechenintensive Operation, die sich leicht parallelisieren lässt. Durch die Größe der Matrizen lässt sich außerdem die Arbeitslast gut skalieren.
		\item \textbf{Kopieren von Arrays} ist eine Operation, die wenig Rechenleistung benötigt, aber die Speicherbandbreite stark auslastet. Zudem lässt sich hier die Arbeitslast ebenfalls gut durch die Größe des Arrays skalieren.
	\end{itemize}
	
	\section*{Implementierungsdetails}
	\subsection*{Generelles}
	Die oben genannten APIs verwenden sogenannte Command-Queues, um unter anderem Kopier-Operationen asynchron zu verarbeiten.
	Da ich nur die Laufzeit des tatsächlichen Kernel-Pro-gramms messen möchte und die Zeit, die das Kopieren vom/zum Host ausgespart werden soll, ist es wichtig sicherzustellen, dass diese Operationen vor Beginn der Zeitmessung abgeschlossen sind.
	Glücklicherweise gibt es dafür passende Funktionen, wie z.B. \texttt{queue.flush()} bei OpenCL oder eine synchrone Kopier-Methode \texttt{Driver.memcpy\_htod} bei CUDA.
	Auch die eigentliche Ausführung der Kernels findet normalerweise asynchron statt, hier kann bei OpenCL zur Synchronisierung eine \texttt{wait()}-Methode aufgerufen werden, bei CUDA kann der selbe Effekt durch einen Aufruf von \texttt{Context.synchronize()} erzielt werden.
	
	\subsection*{Matrix-Multiplikation}
	Hier werden als Eingabe zwei zufällig generierte 10000x10000-Matrizen verwendet, die dann naiv multipliziert werden. Hier berechnet jede Arbeitseinheit auf der GPU ein Feld der resultierenden Matrix.
	Da hier das Kopieren der Daten nur einen winzigen Bruchteil der Laufzeit ausmacht, wird das Ergebnis zurückgeschrieben und teilweise ausgegeben.
	Die Laufzeitmessung beschränkt sich allerdings trotzdem nur auf die eigentliche Berechnung.
	
	Das Programm wird 100 mal iteriert, wobei hier jedes mal die selben Operanden verwendet werden: Zu Beginn werden die Eingabematrizen erstellt und auf die GPU kopiert, dann wird die Berechnung 100 mal wiederholt.
	
	\subsection*{Copy-Kernel}
	Als Eingabe wird hier ein Array von 32-Bit Floats verwendet, wobei jede Arbeitseinheit je eine der Zahlen in ein gleich großes Ausgabearray kopiert.
	Die Größe des Arrays wird an den verfügbaren GPU-Speicher angepasst, um diesen optimal auszunutzen.
	Hier ist es besonders wichtig, die Kopiervorgänge zur GPU nicht in die Zeitmessung mit aufzunehmen, da diese deutlich länger dauern als die Kernelausführung.
	
	\section*{Testsysteme}
	Hier kurz die technischen Daten der Grafikkarten, die ich in meinem Test verwendet habe:
	
	\subsection*{Testsystem 1: NVIDIA}
	\begin{tabular}{@{}ll@{}}
		\toprule
		\textbf{Eigenschaft}             & \textbf{Wert}                      \\ \midrule
		\textbf{Bezeichnung}			& NVidia GeForce RTX 2060			\\
		\textbf{GPU-Kerne (CUDA Cores)} & 1920                               \\
		\textbf{Basistakt}              & 1365 MHz                           \\
		\textbf{Boost-Takt}             & 1680 MHz                           \\
		\textbf{Speichergröße}          & 6 GB GDDR6                         \\
		\textbf{Speicherinterface}      & 192 Bit                            \\
		\textbf{Speicherbandbreite}     & 336 GB/s                           \\
		\textbf{Speichertakt}           & 14 Gbps (effektiv)                 \\
		\bottomrule
	\end{tabular}
	
	\subsection*{Testsystem 2: Intel}
	\begin{tabular}{@{}ll@{}}
		\toprule
		\textbf{Eigenschaft}             & \textbf{Wert}                         \\ \midrule
		\textbf{Bezeichnung}		     & Intel Arc A770 (Limited Edition)		\\
		\textbf{GPU-Kerne (Shader)}      & 4096                                   \\
		\textbf{Basistakt}               & 2100 MHz                              \\
		\textbf{Boost-Takt}              & Bis zu 2400 MHz                       \\
		\textbf{Speichergröße}           & 16 GB GDDR6                           \\
		\textbf{Speicherinterface}       & 256 Bit                               \\
		\textbf{Speicherbandbreite}      & 560 GB/s                              \\
		\textbf{Speichertakt}            & 17.5 Gbps (effektiv)                  \\
		\bottomrule
	\end{tabular}
	
	
	
	
	
	
	
	
	
	
	
\end{document}